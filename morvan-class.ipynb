{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\n\nn_data=torch.ones(100, 2)\n\nx0=torch.normal(2*n_data, 1)\ny0=torch.zeros(100)\n\nx1=torch.normal(-2*n_data, 1)\ny1=torch.ones(100)\n\nx=torch.cat((x0, x1), 0).type(torch.FloatTensor)\ny=torch.cat((y0, y1), 0).type(torch.LongTensor)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x[:,0].data.numpy(), x[:, 1].data.numpy(), c=y)\n#plt.scatter(x1[:,0].data.numpy(), x1[:, 1].data.numpy())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\nclass Net(torch.nn.Module):\n    def __init__(self, n_feature, n_hidden, n_output):\n        super(Net, self).__init__()\n        self.hidden=torch.nn.Linear(n_feature, n_hidden)\n        self.out=torch.nn.Linear(n_hidden, n_output)\n        \n    def forward(self, x):\n        x=F.relu(self.hidden(x))\n        x=self.out(x)\n        return x\n    \nnet=Net(n_feature=2, n_hidden=10, n_output=2)\nprint(net)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer=torch.optim.SGD(net.parameters(), lr=0.02)\nloss_func=torch.nn.CrossEntropyLoss()\n\n# for i in range(100):\nout=net(x)\nloss=loss_func(out, y)\n    \noptimizer.zero_grad()\nloss.backward()\noptimizer.step()\n\nprediction=torch.max(F.softmax(out), 1)[1]\n#print(out)\n#print(F.softmax(out))\n#print(torch.max(F.softmax(out), 1))\n#print(prediction)\n# pred_y=prediction.data.numpy.squeeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.ion()\n\noptimizer=torch.optim.SGD(net.parameters(), lr=0.02)\nloss_func=torch.nn.CrossEntropyLoss()\n\nfor t in range(100):    \n    out=net(x)\n    loss=loss_func(out, y)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    if t%2==0:\n        plt.cla()\n        prediction=torch.max(F.softmax(out), 1)[1]\n        pred_y=prediction.data.numpy().squeeze()\n        target_y=y.data.numpy()\n        plt.scatter(x.data.numpy()[:, 0], x.data.numpy()[:, 1], c=pred_y, s=100, lw=0, cmap=\"RdYlGn\")\n        accuracy=sum(pred_y==target_y)/200\n        plt.text(1.5, -4, 'Accuracy=%.2f' % accuracy, fontdict={'size': 20, 'color': 'red'})\n        plt.pause(0.1)\n\nplt.ioff()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}