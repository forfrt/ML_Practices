{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# [1-4,时间序列数据建模流程范例](https://lyhue1991.github.io/eat_tensorflow2_in_30_days/1-4,%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%B5%81%E7%A8%8B%E8%8C%83%E4%BE%8B.html)\n# https://blog.csdn.net/weixin_45158404/article/details/104720365\n# [新冠肺炎Covid-19数据分析](https://zhuanlan.zhihu.com/p/109556102)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install tushare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tushare as ts\npro = ts.pro_api(\"ad41a74271c5e6ba99f5c9dc43c9a1be75bdde38e7e679a732afd7f9\")#需要在tushare免费注册一个账号，填入你的token即可调取数据\ndf = pro.ncov_num(level=2)\n#df1 = pro.ncov_num(start_date='20200124',end_date='20200507')#最早是从2020年1月24日开始的数据\ndf.to_csv('covid19.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf \nfrom tensorflow.keras import models,layers,losses,metrics,callbacks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom glob import glob\nresult = [y for x in os.walk('/kaggle') for y in glob(os.path.join(x[0], '*'))]\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\ndf = pd.read_csv(\"/kaggle/working/covid19.csv\",sep = \",\")\ndf['ann_date']=df['ann_date'].apply(lambda x: datetime.strptime(str(x), '%Y%m%d'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(x = \"ann_date\",y = [\"confirmed_num\",\"cured_num\",\"dead_num\"],figsize=(10,6))\nplt.xticks(rotation=60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data=df.drop(['Unnamed: 0', 'area_name', 'parent_name', 'suspected_num', 'confirmed_num_now', 'suspected_num_now', 'level'], axis=1)\ndf_data=df_data.set_index(\"ann_date\")\ndfdiff=df_data.diff(periods=1).dropna()\ndfdiff = dfdiff.reset_index(level=\"ann_date\")\n#print(dfdiff)\n\ndfdiff.plot(x = \"ann_date\",y = [\"confirmed_num\",\"cured_num\",\"dead_num\"],figsize=(10,6))\nplt.xticks(rotation=60)\ndfdiff = dfdiff.drop(\"ann_date\",axis = 1).astype(\"float32\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdiff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WINDOW_SIZE=8\n\ndef batch_dataset(dataset):\n    dataset_batched=dataset.batch(WINDOW_SIZE, drop_remainder=True)\n    return dataset_batched\n\nds_data=tf.data.Dataset.from_tensor_slices(tf.constant(dfdiff.values, dtype=tf.float32)) \\\n.window(WINDOW_SIZE, shift=1).flat_map(batch_dataset)\n# ds_data=tf.data.Dataset.from_tensor_slices(tf.constant(dfdiff.values, dtype=tf.float32)) \\\n# .window(WINDOW_SIZE, shift=1)\n# ds_data=ds_data.flat_map(lambda window: window.batch(WINDOW_SIZE))\n\nds_label=tf.data.Dataset.from_tensor_slices(tf.constant(dfdiff.values[WINDOW_SIZE:], dtype=tf.float32))\n\nds_train=tf.data.Dataset.zip((ds_data, ds_label)).batch(38).cache()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ds_data\", list(ds_data.as_numpy_iterator())[0])\nprint(\"ds_label\", list(ds_label.as_numpy_iterator())[0])\n\nx, y=next(ds_train.as_numpy_iterator())\nprint(\"ds_train\", x.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 定义模型","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Block(layers.Layer):\n    def __init__(self, **kwargs):\n        super(Block, self).__init__(**kwargs)\n        \n    def call(self, x_input, x):\n        print(\"Block layer: x_input: \", x_input.shape, x_input[:,-1,:])\n        print(\"Block layer: x: \", x.shape, x)\n        x_out=tf.maximum((x)*x_input[:, -1, :], 0.0)\n        return x_out\n    \n    def get_config(self):\n        config=super(Block, self).get_config()\n        return config","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.backend.clear_session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_input=layers.Input(shape=(None, 3), dtype=tf.float32)\nx=layers.LSTM(3, return_sequences=True, input_shape=(None,3))(x_input)\nx=layers.LSTM(3, return_sequences=True, input_shape=(None,3))(x)\nx=layers.LSTM(3, return_sequences=True, input_shape=(None,3))(x)\nx=layers.LSTM(3, input_shape=(None,3))(x)\nx=layers.Dense(3)(x)\n\nx=Block()(x_input, x)\nmodel=models.Model(inputs=[x_input], outputs=[x])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MSPE(losses.Loss):\n    def call(self, y_true, y_pred):\n        err_percent=(y_true-y_pred)**2/(tf.maximum(y_true**2, 1e-7))\n        mean_err_percent=tf.reduce_mean(err_percent)\n        return mean_err_percent\n\n    def get_config(self):\n        config=super(MSPE, self).get_config()\n        return config","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\noptimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\nmodel.compile(optimizer=optimizer, loss=MSPE(name=\"MSPE\"))\n\nlogdir = \"./data/keras_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ntb_callback=tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\nlr_callback=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=100)\nstop_callback=tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=200)\ncallbacks_list=[tb_callback, lr_callback, stop_callback]\n\nhistory=model.fit(ds_train, epochs=500, callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_input=layers.Input(shape=(4, 3), dtype=tf.float32)\ntest_input.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}