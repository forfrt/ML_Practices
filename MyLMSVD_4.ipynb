{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"MyLMSVD_4.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KfApMEiSiBvB","colab_type":"code","outputId":"f2bb2ee7-cb92-4f0b-fc66-704935e14dc7","executionInfo":{"status":"ok","timestamp":1574367934025,"user_tz":-480,"elapsed":181437,"user":{"displayName":"Ruitao Feng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB2lcWfJsT8OzTTu2cDwRFAbYw0w87EhuWZ-6L9=s64","userId":"11622521707866532302"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"XPx8O-ffhYDl","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.nn import Parameter\n","from torch.nn.utils import clip_grad_norm\n","\n","import torchtext\n","from torchtext import *\n","from fastai.text import *\n","from fastai.callbacks import *\n","\n","import pandas as pd\n","import random\n","from itertools import chain\n","import math\n","import numpy as np\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"wZPgG01PhYDo","colab_type":"code","colab":{}},"source":["def random_seed(seed_value, use_cuda):\n","  np.random.seed(seed_value) # cpu vars\n","  torch.manual_seed(seed_value) # cpu  vars\n","  random.seed(seed_value) # Python\n","  if use_cuda:\n","    torch.cuda.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value) # gpu vars\n","    torch.backends.cudnn.deterministic = True  #needed\n","    torch.backends.cudnn.benchmark = False\n","random_seed(180127818, True)\n","#torch.cuda.set_device(0)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"0xCVxpychYDs","colab_type":"code","colab":{}},"source":["# Wikitext-2\n","path = '/content/drive/My Drive/wikitext-2/'\n","#epoch number, follow https://github.com/fastai/fastai/blob/master/examples/ULMFit.ipynb\n","lm_epoch = 10\n","cls_epoch = 2\n","bptt=70\n","bs=32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzB9nIJ5idFA","colab_type":"code","outputId":"b568eece-b6ba-46fd-f36e-887aef11dcc2","executionInfo":{"status":"ok","timestamp":1574367937732,"user_tz":-480,"elapsed":185113,"user":{"displayName":"Ruitao Feng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB2lcWfJsT8OzTTu2cDwRFAbYw0w87EhuWZ-6L9=s64","userId":"11622521707866532302"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My\\ Drive/"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"IAsv-HqQhYDv","colab_type":"code","outputId":"efd35b88-36a7-46c5-fb1b-dbbdc3eb129a","executionInfo":{"status":"ok","timestamp":1574367941736,"user_tz":-480,"elapsed":189102,"user":{"displayName":"Ruitao Feng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB2lcWfJsT8OzTTu2cDwRFAbYw0w87EhuWZ-6L9=s64","userId":"11622521707866532302"}},"colab":{"base_uri":"https://localhost:8080/","height":262}},"source":["!wget https://s3.amazonaws.com/fast-ai-nlp/wikitext-2.tgz\n","!tar -zxvf wikitext-2.tgz"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2019-11-21 20:25:37--  https://s3.amazonaws.com/fast-ai-nlp/wikitext-2.tgz\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.95.69\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.95.69|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4070055 (3.9M) [application/x-tar]\n","Saving to: ‘wikitext-2.tgz.2’\n","\n","wikitext-2.tgz.2    100%[===================>]   3.88M  7.68MB/s    in 0.5s    \n","\n","2019-11-21 20:25:38 (7.68 MB/s) - ‘wikitext-2.tgz.2’ saved [4070055/4070055]\n","\n","wikitext-2/\n","wikitext-2/train.csv\n","wikitext-2/test.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"AHI0v8xbhYD2","colab_type":"code","colab":{}},"source":["train=pd.read_csv('./wikitext-2/train.csv',header=None,sep='/n/t/n/t', engine='python')\n","test=pd.read_csv('./wikitext-2/test.csv',header=None,sep='/n/t/n/t', engine='python')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"w4cC6qHshYD5","colab_type":"code","colab":{}},"source":["# CREATE data\n","# Language model data bunch\n","data_lm = TextLMDataBunch.from_df('.',train_df=train,valid_df=test,text_cols=0)\n","data_lm.save(path+'data_lm.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"2kuV4ByBhYD8","colab_type":"code","colab":{}},"source":["# LOAD data & learner\n","#forward\n","data_lm = load_data(path, 'data_lm.pkl', bs=bs, bptt=bptt)\n","#bwd\n","#data_bwd = load_data(path, 'data_lm.pkl', bs=128, bptt=70, backwards=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"YVnzX0w7hYEC","colab_type":"code","outputId":"b237402a-7184-437c-f95d-c0a2a02e450b","executionInfo":{"status":"ok","timestamp":1574368076529,"user_tz":-480,"elapsed":100140,"user":{"displayName":"Ruitao Feng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB2lcWfJsT8OzTTu2cDwRFAbYw0w87EhuWZ-6L9=s64","userId":"11622521707866532302"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["learn = language_model_learner(data_lm, AWD_LSTM, pretrained=True)\n","# learn = learn.to_fp16(clip=0.1)\n","learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7), wd=0.1)\n","#learn_bwd = language_model_learner(data_bwd, AWD_LSTM, pretrained=True)\n","#learn_bwd = learn_bwd.to_fp16(clip=0.1)\n","#learn_bwd.fit_one_cycle(1, 1e-2, moms=(0.8,0.7), wd=0.1)"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>3.783408</td>\n","      <td>3.418671</td>\n","      <td>0.364780</td>\n","      <td>01:39</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"trusted":true,"id":"OnvTc27VhYEF","colab_type":"code","colab":{}},"source":["learn.save('learn')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"QNigG8DkhYEI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3be18da9-3431-47cc-fb26-cedfb0496e07","executionInfo":{"status":"ok","timestamp":1574368078389,"user_tz":-480,"elapsed":325723,"user":{"displayName":"Ruitao Feng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB2lcWfJsT8OzTTu2cDwRFAbYw0w87EhuWZ-6L9=s64","userId":"11622521707866532302"}}},"source":["learn = language_model_learner(data_lm, AWD_LSTM, pretrained=False)\n","learn.load('learn')"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LanguageLearner(data=TextLMDataBunch;\n","\n","Train: LabelList (24974 items)\n","x: LMTextList\n","xxbos \",xxbos = 2013 – 14 xxmaj york xxmaj city xxup f.c. season =,xxbos xxmaj the 2013 – 14 season was the xxunk season of competitive association football and 77th season in the xxmaj football xxmaj league played by xxmaj york xxmaj city xxmaj football xxmaj club , a professional football club based in xxmaj york , xxmaj north xxmaj yorkshire , xxmaj england . xxmaj their 17th - place finish in 2012 – 13 meant it was their second consecutive season in xxmaj league xxmaj two . xxmaj the season ran from 1 xxmaj july 2013 to 30 xxmaj june 2014 .,xxbos xxmaj nigel xxmaj worthington , starting his first full season as xxmaj york manager , made eight permanent summer signings . xxmaj by the turn of the year xxmaj york were only above the relegation zone on goal difference , before a 17-match unbeaten run saw the team finish in seventh - place in the xxunk 2013 – 14 xxmaj football xxmaj league xxmaj two . xxmaj this meant xxmaj york qualified for the play - offs , and they were eliminated in the semi - final by xxmaj fleetwood xxmaj town . xxmaj york were knocked out of the 2013 – 14 xxup fa xxmaj cup , xxmaj football xxmaj league xxmaj cup and xxmaj football xxmaj league xxmaj trophy in their opening round matches .,xxbos 35 players made at least one appearance in nationally organised first - team competition , and there were 12 different xxunk . xxmaj defender xxmaj ben xxmaj davies missed only five of the fifty - two competitive matches played over the season . xxmaj wes xxmaj fletcher finished as leading scorer with 13 goals , of which 10 came in league competition and three came in the xxup fa xxmaj cup . xxmaj the winner of the xxunk of the xxmaj year award , voted for by the club 's supporters , was xxunk xxmaj oyebanjo .\n","y: LMLabelList\n",",,,,\n","Path: .;\n","\n","Valid: LabelList (2555 items)\n","x: LMTextList\n","xxbos \",xxbos = xxmaj tropical xxmaj storm xxunk ( 2008 ) =,xxbos xxmaj tropical xxmaj storm xxunk was the tenth tropical storm of the 2008 xxmaj atlantic hurricane season . xxunk developed out of a strong tropical wave which moved off the xxmaj african coast on xxmaj august 31 . xxmaj the wave quickly became organized and was declared xxmaj tropical xxmaj depression xxmaj ten while located 170 mi ( 270 km ) to the south - southeast of the xxmaj cape xxmaj verde xxmaj islands on xxmaj september 2 . xxmaj the depression was quickly upgraded to xxmaj tropical xxmaj storm xxunk around noon the same day . xxmaj over the next several days , xxunk moved in a general west - northwest direction and reached its peak intensity early on xxmaj september 3 . xxmaj strong wind shear , some due to the outflow of xxmaj hurricane xxmaj ike , and dry air caused the storm to weaken . xxmaj on xxmaj september 6 , the combination of wind shear , dry air , and cooling waters caused xxunk to weaken into a tropical depression . xxunk deteriorated into a remnant low shortly after as convection continued to dissipate around the storm . xxmaj the low ultimately dissipated while located 520 mi ( 835 km ) east of xxunk on xxmaj september 10 . xxmaj however , the remnant moisture led to minor flooding on the island of xxmaj st. xxmaj croix .,xxbos = = xxmaj meteorological history = =,xxbos xxmaj tropical xxmaj storm xxunk formed as a tropical wave that emerged off the west coast of xxmaj africa near the end of xxmaj august 2008 . xxmaj it tracked south of xxmaj cape xxmaj verde and slowly developed , and on xxmaj september 2 the disturbance became xxmaj tropical xxmaj depression xxmaj ten while located south - southeast of the xxmaj cape xxmaj verde islands . xxmaj as the depression became more organized , an eye - like feature developed in the upper levels of the system . xxmaj the depression was upgraded to xxmaj tropical xxmaj storm xxunk six hours after forming . xxunk was located in an area which was supportive for rapid intensification but was not forecast to intensify quickly .\n","y: LMLabelList\n",",,,,\n","Path: .;\n","\n","Test: None, model=SequentialRNN(\n","  (0): AWD_LSTM(\n","    (encoder): Embedding(29736, 400, padding_idx=1)\n","    (encoder_dp): EmbeddingDropout(\n","      (emb): Embedding(29736, 400, padding_idx=1)\n","    )\n","    (rnns): ModuleList(\n","      (0): WeightDropout(\n","        (module): LSTM(400, 1152, batch_first=True)\n","      )\n","      (1): WeightDropout(\n","        (module): LSTM(1152, 1152, batch_first=True)\n","      )\n","      (2): WeightDropout(\n","        (module): LSTM(1152, 400, batch_first=True)\n","      )\n","    )\n","    (input_dp): RNNDropout()\n","    (hidden_dps): ModuleList(\n","      (0): RNNDropout()\n","      (1): RNNDropout()\n","      (2): RNNDropout()\n","    )\n","  )\n","  (1): LinearDecoder(\n","    (decoder): Linear(in_features=400, out_features=29736, bias=True)\n","    (output_dp): RNNDropout()\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9bfbc8d7b8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/drive/My Drive/wikitext-2'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n","learn: LanguageLearner(data=TextLMDataBunch;\n","\n","Train: LabelList (24974 items)\n","x: LMTextList\n","xxbos \",xxbos = 2013 – 14 xxmaj york xxmaj city xxup f.c. season =,xxbos xxmaj the 2013 – 14 season was the xxunk season of competitive association football and 77th season in the xxmaj football xxmaj league played by xxmaj york xxmaj city xxmaj football xxmaj club , a professional football club based in xxmaj york , xxmaj north xxmaj yorkshire , xxmaj england . xxmaj their 17th - place finish in 2012 – 13 meant it was their second consecutive season in xxmaj league xxmaj two . xxmaj the season ran from 1 xxmaj july 2013 to 30 xxmaj june 2014 .,xxbos xxmaj nigel xxmaj worthington , starting his first full season as xxmaj york manager , made eight permanent summer signings . xxmaj by the turn of the year xxmaj york were only above the relegation zone on goal difference , before a 17-match unbeaten run saw the team finish in seventh - place in the xxunk 2013 – 14 xxmaj football xxmaj league xxmaj two . xxmaj this meant xxmaj york qualified for the play - offs , and they were eliminated in the semi - final by xxmaj fleetwood xxmaj town . xxmaj york were knocked out of the 2013 – 14 xxup fa xxmaj cup , xxmaj football xxmaj league xxmaj cup and xxmaj football xxmaj league xxmaj trophy in their opening round matches .,xxbos 35 players made at least one appearance in nationally organised first - team competition , and there were 12 different xxunk . xxmaj defender xxmaj ben xxmaj davies missed only five of the fifty - two competitive matches played over the season . xxmaj wes xxmaj fletcher finished as leading scorer with 13 goals , of which 10 came in league competition and three came in the xxup fa xxmaj cup . xxmaj the winner of the xxunk of the xxmaj year award , voted for by the club 's supporters , was xxunk xxmaj oyebanjo .\n","y: LMLabelList\n",",,,,\n","Path: .;\n","\n","Valid: LabelList (2555 items)\n","x: LMTextList\n","xxbos \",xxbos = xxmaj tropical xxmaj storm xxunk ( 2008 ) =,xxbos xxmaj tropical xxmaj storm xxunk was the tenth tropical storm of the 2008 xxmaj atlantic hurricane season . xxunk developed out of a strong tropical wave which moved off the xxmaj african coast on xxmaj august 31 . xxmaj the wave quickly became organized and was declared xxmaj tropical xxmaj depression xxmaj ten while located 170 mi ( 270 km ) to the south - southeast of the xxmaj cape xxmaj verde xxmaj islands on xxmaj september 2 . xxmaj the depression was quickly upgraded to xxmaj tropical xxmaj storm xxunk around noon the same day . xxmaj over the next several days , xxunk moved in a general west - northwest direction and reached its peak intensity early on xxmaj september 3 . xxmaj strong wind shear , some due to the outflow of xxmaj hurricane xxmaj ike , and dry air caused the storm to weaken . xxmaj on xxmaj september 6 , the combination of wind shear , dry air , and cooling waters caused xxunk to weaken into a tropical depression . xxunk deteriorated into a remnant low shortly after as convection continued to dissipate around the storm . xxmaj the low ultimately dissipated while located 520 mi ( 835 km ) east of xxunk on xxmaj september 10 . xxmaj however , the remnant moisture led to minor flooding on the island of xxmaj st. xxmaj croix .,xxbos = = xxmaj meteorological history = =,xxbos xxmaj tropical xxmaj storm xxunk formed as a tropical wave that emerged off the west coast of xxmaj africa near the end of xxmaj august 2008 . xxmaj it tracked south of xxmaj cape xxmaj verde and slowly developed , and on xxmaj september 2 the disturbance became xxmaj tropical xxmaj depression xxmaj ten while located south - southeast of the xxmaj cape xxmaj verde islands . xxmaj as the depression became more organized , an eye - like feature developed in the upper levels of the system . xxmaj the depression was upgraded to xxmaj tropical xxmaj storm xxunk six hours after forming . xxunk was located in an area which was supportive for rapid intensification but was not forecast to intensify quickly .\n","y: LMLabelList\n",",,,,\n","Path: .;\n","\n","Test: None, model=SequentialRNN(\n","  (0): AWD_LSTM(\n","    (encoder): Embedding(29736, 400, padding_idx=1)\n","    (encoder_dp): EmbeddingDropout(\n","      (emb): Embedding(29736, 400, padding_idx=1)\n","    )\n","    (rnns): ModuleList(\n","      (0): WeightDropout(\n","        (module): LSTM(400, 1152, batch_first=True)\n","      )\n","      (1): WeightDropout(\n","        (module): LSTM(1152, 1152, batch_first=True)\n","      )\n","      (2): WeightDropout(\n","        (module): LSTM(1152, 400, batch_first=True)\n","      )\n","    )\n","    (input_dp): RNNDropout()\n","    (hidden_dps): ModuleList(\n","      (0): RNNDropout()\n","      (1): RNNDropout()\n","      (2): RNNDropout()\n","    )\n","  )\n","  (1): LinearDecoder(\n","    (decoder): Linear(in_features=400, out_features=29736, bias=True)\n","    (output_dp): RNNDropout()\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f9bfbc8d7b8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/drive/My Drive/wikitext-2'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): Embedding(29736, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(29736, 400, padding_idx=1)\n","  )\n","  (2): LinearDecoder(\n","    (decoder): Linear(in_features=400, out_features=29736, bias=True)\n","    (output_dp): RNNDropout()\n","  )\n",")], add_time=True, silent=False)\n","alpha: 2.0\n","beta: 1.0], layer_groups=[Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): Embedding(29736, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(29736, 400, padding_idx=1)\n","  )\n","  (2): LinearDecoder(\n","    (decoder): Linear(in_features=400, out_features=29736, bias=True)\n","    (output_dp): RNNDropout()\n","  )\n",")], add_time=True, silent=False)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"trusted":true,"id":"R92CMwWnhYEL","colab_type":"code","colab":{}},"source":["class LinearSVDO(nn.Module):\n","  def __init__(self, in_features, out_features):\n","    super(LinearSVDO, self).__init__()\n","    self.is_training = 1\n","    self.in_features = in_features\n","    self.out_features = out_features\n","    self.weight = Parameter(torch.Tensor(out_features, in_features))\n","    self.log_sigma = Parameter(torch.Tensor(out_features, in_features))\n","    self.bias = Parameter(torch.Tensor(1, out_features))\n","    self.reset_parameters()\n","  \n","  def reset_training(self, v=0):\n","    self.is_training = v\n","\n","  def reset_parameters(self):\n","    self.bias.data.zero_()\n","    self.weight.data.normal_(0, 0.02)\n","    self.log_sigma.data.fill_(-5)        \n","        \n","  def forward(self, x):\n","    self.log_alpha = self.log_sigma * 2.0 - 2.0 * torch.log(1e-16 + torch.abs(self.weight))\n","    self.log_alpha = torch.clamp(self.log_alpha, -10, 10) \n","    lrt_mean =  F.linear(x, self.weight) + self.bias    \n","    if self.training: \n","      lrt_std = torch.sqrt(F.linear(x * x, torch.exp(self.log_sigma * 2.0)) + 1e-8)\n","      eps = lrt_std.data.new(lrt_std.size()).normal_()\n","      return lrt_mean + lrt_std * eps\n","    return lrt_mean\n","        \n","  def kl_reg(self):\n","    # Return KL here -- a scalar \n","    k1, k2, k3 = torch.Tensor([0.63576]).to(device), torch.Tensor([1.8732]).to(device), torch.Tensor([1.48695]).to(device)\n","    kl = k1 * torch.sigmoid(k2 + k3 * self.log_alpha) - 0.5 * torch.log1p(torch.exp(-self.log_alpha))\n","    a = - torch.sum(kl)\n","    return a"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"7N7Clyx-hYEQ","colab_type":"code","colab":{}},"source":["class LSTMSVDO(nn.Module):\n","  def __init__(self, input_sz: int, hidden_sz: int):\n","    super().__init__()\n","    self.is_training = 1\n","    self.input_sz = input_sz\n","    self.hidden_size = hidden_sz\n","    self.weight_ih = Parameter(torch.Tensor(hidden_sz * 4, input_sz))\n","    self.weight_hh = Parameter(torch.Tensor(hidden_sz * 4, hidden_sz))\n","    self.log_sigma_ih = Parameter(torch.Tensor(hidden_sz * 4, input_sz))\n","    self.log_sigma_hh = Parameter(torch.Tensor(hidden_sz * 4, hidden_sz))\n","    self.bias = Parameter(torch.Tensor(hidden_sz * 4))\n","    self.reset_parameters()\n","  \n","  def reset_training(self, v=0):\n","    self.is_training = v\n","    \n","  def reset_parameters(self):\n","    self.bias.data.zero_()\n","    self.weight_ih.data.normal_(0, 0.02)\n","    self.weight_hh.data.normal_(0, 0.02)\n","    self.log_sigma_ih.data.fill_(-5)\n","    self.log_sigma_hh.data.fill_(-5)\n","\n","  def forward(self, x: torch.Tensor, init_states=None):\n","    \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n","    self.log_alpha_ih = torch.clamp(self.log_sigma_ih * 2.0 - 2.0 * torch.log(1e-16 + torch.abs(self.weight_ih)), -10, 10) \n","    self.log_alpha_hh = torch.clamp(self.log_sigma_hh * 2.0 - 2.0 * torch.log(1e-16 + torch.abs(self.weight_hh)), -10, 10) \n","    bs, seq_sz, _ = x.size()\n","    hidden_seq = []\n","    if init_states is None:\n","      h_t, c_t = (torch.zeros(self.hidden_size).to(x.device), torch.zeros(self.hidden_size).to(x.device))\n","    else:\n","      h_t, c_t = init_states \n","    HS = self.hidden_size\n","    for t in range(seq_sz):\n","      x_t = x[:, t, :]\n","      # batch the computations into a single matrix multiplication\n","      if self.is_training:\n","        lrt_std_ih = torch.sqrt(F.linear((x_t * x_t), torch.exp(self.log_sigma_ih * 2.0)) + 1e-8)\n","        lrt_std_hh = torch.sqrt(F.linear((h_t * h_t), torch.exp(self.log_sigma_hh * 2.0)) + 1e-8)\n","        eps_ih = lrt_std_ih.data.new(lrt_std_ih.size()).normal_()\n","        eps_hh = lrt_std_hh.data.new(lrt_std_hh.size()).normal_()\n","\n","        gates = F.linear(x_t, self.weight_ih) + F.linear(h_t, self.weight_hh) + self.bias + lrt_std_ih * eps_ih + lrt_std_hh * eps_hh\n","      else:\n","        gates = F.linear(x_t, self.weight_ih) + F.linear(h_t, self.weight_hh) + self.bias\n","      i_t, f_t, g_t, o_t = (\n","          torch.sigmoid(gates[:, :HS]), # input\n","          torch.sigmoid(gates[:, HS:HS*2]), # forget\n","          torch.tanh(gates[:, HS*2:HS*3]),\n","          torch.sigmoid(gates[:, HS*3:]), # output\n","          )\n","      c_t = f_t * c_t + i_t * g_t\n","      h_t = o_t * torch.tanh(c_t)\n","      hidden_seq.append(h_t.unsqueeze(0))\n","    hidden_seq = torch.cat(hidden_seq, dim=0)\n","    h_t, c_t = h_t.detach(), c_t.detach()\n","    # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n","    hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n","    return hidden_seq#, (h_t, c_t)\n","\n","          \n","  def kl_reg(self):\n","    # Return KL here -- a scalar \n","    a_sum = torch.Tensor([0.]).to(device)\n","    k1, k2, k3 = torch.Tensor([0.63576]).to(device), torch.Tensor([1.8732]).to(device), torch.Tensor([1.48695]).to(device)\n","    for log_alpha in [self.log_alpha_ih, self.log_alpha_hh]:\n","      kl = k1 * torch.sigmoid(k2 + k3 * log_alpha) - 0.5 * torch.log1p(torch.exp(-log_alpha))\n","      a = - torch.sum(kl)\n","      a_sum = a_sum + a\n","    return a_sum"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"YK00qM0lhYEU","colab_type":"code","colab":{}},"source":["# Define New Loss Function -- SGVLB \n","class SGVLB(nn.modules.loss.Module):\n","  def __init__(self, net, train_size):\n","    super(SGVLB, self).__init__()\n","    self.train_size = train_size\n","    self.net = net\n","\n","  def forward(self, input, target, kl_weight=1.0):\n","    assert not target.requires_grad\n","    kl = 0.0\n","    for module in [self.net.rnn1, self.net.rnn2, self.net.rnn3, self.net.decoder]:#for module in [self.net.rnn1, ]:\n","      if hasattr(module, 'kl_reg'):\n","        kl = kl + module.kl_reg()\n","    return F.nll_loss(input, target) + kl_weight * kl / self.train_size#F.nll_loss(input, target) * self.train_size + kl_weight * kl / bs #cross_entropy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"qV-8nsvwhYEY","colab_type":"code","colab":{}},"source":["# Define a simple 3 layer LSTM\n","class Net(nn.Module):\n","  def __init__(self, vocab_size, num_embed, num_hidden, **kwargs):\n","    super(Net, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, num_embed, padding_idx=1)\n","    self.rnn1 = LSTMSVDO(num_embed, num_hidden)\n","    self.rnn2 = LSTMSVDO(num_hidden, num_hidden)\n","    self.rnn3 = LSTMSVDO(num_hidden, num_embed)\n","    self.decoder = LinearSVDO(num_embed, vocab_size)\n","  \n","  def reset_training(self, v):\n","    for i in [self.rnn1, self.decoder]:#[self.rnn1, self.rnn2, self.rnn3, self.decoder]:\n","      i.reset_training(v)\n","\n","  def forward(self, x: torch.Tensor):\n","    \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n","    x = self.embedding(x)\n","    #init_states = init_states\n","    #x, init_states[0] = self.rnn1(x, init_states[0])\n","    #x, init_states[1] = self.rnn2(F.relu(x), init_states[1])\n","    #x, init_states[2] = self.rnn3(F.relu(x), init_states[2])\n","    x = self.rnn1(x)\n","    x = self.rnn2(F.relu(x))\n","    x = self.rnn3(F.relu(x))\n","    # Reshape output to (batch_size*sequence_length, hidden_size)\n","    x = F.log_softmax(self.decoder(F.relu(x).reshape(x.size(0)*x.size(1),x.size(2))))\n","    #x = F.log_softmax(self.decoder(x[:,-1,:]))\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"LhV2CJ_-hYEb","colab_type":"code","colab":{}},"source":["model = Net(vocab_size=len(data_lm.train_ds.vocab.itos), num_embed=400, num_hidden=1152).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"WisgiIMqhYEe","colab_type":"code","colab":{}},"source":["model.embedding.weight.data = learn.model[0].encoder.weight.data\n","model.rnn1.weight_ih.data = learn.model[0].rnns[0].module.weight_ih_l0.data\n","model.rnn1.weight_hh.data = learn.model[0].rnns[0].module.weight_hh_l0.data\n","model.rnn1.bias.data = learn.model[0].rnns[0].module.bias_ih_l0.data\n","model.rnn2.weight_ih.data = learn.model[0].rnns[1].module.weight_ih_l0.data\n","model.rnn2.weight_hh.data = learn.model[0].rnns[1].module.weight_hh_l0.data\n","model.rnn2.bias.data = learn.model[0].rnns[1].module.bias_ih_l0.data\n","model.rnn3.weight_ih.data = learn.model[0].rnns[2].module.weight_ih_l0.data\n","model.rnn3.weight_hh.data = learn.model[0].rnns[2].module.weight_hh_l0.data\n","model.rnn3.bias.data = learn.model[0].rnns[2].module.bias_ih_l0.data\n","model.decoder.weight.data = learn.model[1].decoder.weight.data\n","model.decoder.bias.data = learn.model[1].decoder.bias.data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"_KQ7HTRThYEi","colab_type":"code","colab":{}},"source":["def create_lmdata(data):\n","    ids = torch.LongTensor(list(chain(*data)))\n","    num_batches = ids.size(0) // bs\n","    ids = ids[:num_batches*bs]\n","    ids = ids.view(bs, -1)\n","    return ids\n","ids = create_lmdata(data_lm.train_ds.x.items)\n","valid_ids = create_lmdata(data_lm.valid_ds.x.items)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"VeLJnlvuhYEl","colab_type":"code","colab":{}},"source":["optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50,60,70,80], gamma=0.2)\n","sgvlb = SGVLB(model, ids.shape[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"O7b77mjuhYEo","colab_type":"code","colab":{}},"source":["def myeval(ids=valid_ids):\n","    # use in testing time, so use is_traing=0\n","    total_L = 0.\n","    model.reset_training(0)\n","    criterion = nn.modules.loss.NLLLoss()\n","    for i in range(0, ids.size(1) - bptt, bptt):\n","        # Get mini-batch inputs and targets\n","        inputs = ids[:, i:i+bptt].to(device)\n","        targets = ids[:, (i+1):(i+1)+bptt].to(device)\n","        output = model(inputs)\n","        loss = criterion(output, targets.reshape(-1)).item()\n","        total_L += loss\n","    model.reset_training(1)\n","    return total_L"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"97SGjnU9hYEx","colab_type":"code","colab":{}},"source":["criterion = nn.modules.loss.NLLLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"b6pMc8V0hYE4","colab_type":"code","colab":{}},"source":["def train(kl_weight=0.02, epochs=100): \n","    kl_weight = kl_weight\n","    epochs = epochs\n","    for epoch in range(1, epochs + 1):\n","        start_time = time.time()\n","        train_loss, train_acc = 0, 0 \n","        kl_weight = min(kl_weight+0.02,1)\n","        init_states = None\n","        for i in range(0, ids.size(1) - bptt, bptt):\n","            inputs = ids[:, i:i+bptt].to(device)\n","            targets = ids[:, (i+1):(i+1)+bptt].to(device)\n","            output = model(inputs)\n","            #loss = criterion(output, targets.reshape(-1))\n","            loss = sgvlb(output, targets.reshape(-1), kl_weight)\n","            model.zero_grad()\n","            loss.backward()\n","            clip_grad_norm(model.parameters(), 0.5)\n","            optimizer.step()\n","            #if i % 100 == 0:\n","                #print ('Epoch [{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'.format(epoch, epochs, loss.item(), np.exp(loss.item())))\n","        L = myeval(ids=valid_ids)\n","        scheduler.step()\n","        print('Epoch [{}/{}], Valid_Loss: {:.4f}, Perplexity: {:5.2f}, Time: {:.2f}'.format(epoch, epochs, L, np.exp(L), time.time()-start_time))\n","        \n","        if epoch %10==1:\n","            torch.save(model.state_dict(), path+'model_'+str(epoch)+'.pkl')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"wDHh-GR0hYFA","colab_type":"code","outputId":"bd9f19d2-ef9b-47af-807c-4e00633a1593","colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"status":"error","timestamp":1574368690769,"user_tz":-480,"elapsed":938052,"user":{"displayName":"Ruitao Feng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB2lcWfJsT8OzTTu2cDwRFAbYw0w87EhuWZ-6L9=s64","userId":"11622521707866532302"}}},"source":["model.rnn1.reset_training(1)\n","model.decoder.reset_training(1)\n","train(kl_weight=0.02, epochs=100)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch [1/100], Valid_Loss: 470.7178, Perplexity: 2692380942323445042691593046766830443968783677039305317669871611870857856644433121916297639266804293546256625571004126234449917796273469952603080588175530930619736870590455964906818088910806856567483269120.00, Time: 611.09\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-d7c0d30ec1f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-25d31fb12577>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(kl_weight, epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: must be str, not int"]}]},{"cell_type":"code","metadata":{"id":"Cd5qaMgilfKH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}