{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype = torch.FloatTensor\n# S: Symbol that shows starting of decoding input\n# E: Symbol that shows starting of decoding output\n# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n\nchar_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\nnum_dic = {n: i for i, n in enumerate(char_arr)}\n\nseq_data = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'], ['high', 'low']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_dic, len(num_dic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seq2Seq Parameter\nn_step = 5\nn_hidden = 128\nn_class = len(num_dic)\nbatch_size = len(seq_data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_batch(seq_data):\n    input_batch, output_batch, target_batch = [], [], []\n\n    for seq in seq_data:\n        for i in range(2):\n            seq[i] = seq[i] + 'P' * (n_step - len(seq[i]))\n\n        input = [num_dic[n] for n in seq[0]]\n        output = [num_dic[n] for n in ('S' + seq[1])]\n        target = [num_dic[n] for n in (seq[1] + 'E')]\n\n        input_batch.append(np.eye(n_class)[input])\n        output_batch.append(np.eye(n_class)[output])\n        target_batch.append(target) # not one-hot\n\n    # make tensor\n    return Variable(torch.Tensor(input_batch)), Variable(torch.Tensor(output_batch)), Variable(torch.LongTensor(target_batch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_batch, output_batch, target_batch = make_batch(seq_data)\ninput_batch, output_batch, target_batch\n# input_batch.size(), output_batch.size(), target_batch.size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model\nclass Seq2Seq(nn.Module):\n    def __init__(self):\n        super(Seq2Seq, self).__init__()\n\n        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n        self.fc = nn.Linear(n_hidden, n_class)\n\n    def forward(self, enc_input, enc_hidden, dec_input):\n        enc_input = enc_input.transpose(0, 1) # enc_input: [max_len(=n_step, time step), batch_size, n_class]\n        dec_input = dec_input.transpose(0, 1) # dec_input: [max_len(=n_step, time step), batch_size, n_class]\n\n        # enc_states : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n        _, enc_states = self.enc_cell(enc_input, enc_hidden)\n        # outputs : [max_len+1(=6), batch_size, num_directions(=1) * n_hidden(=128)]\n        outputs, _ = self.dec_cell(dec_input, enc_states)\n\n        model = self.fc(outputs) # model : [max_len+1(=6), batch_size, n_class]\n        return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Seq2Seq()\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(5000):\n    # make hidden shape [num_layers * num_directions, batch_size, n_hidden]\n    hidden = Variable(torch.zeros(1, batch_size, n_hidden))\n\n    optimizer.zero_grad()\n    # input_batch : [batch_size, max_len(=n_step, time step), n_class]\n    # output_batch : [batch_size, max_len+1(=n_step, time step) (becase of 'S' or 'E'), n_class]\n    # target_batch : [batch_size, max_len+1(=n_step, time step)], not one-hot\n    output = model(input_batch, hidden, output_batch)\n    # output : [max_len+1, batch_size, num_directions(=1) * n_hidden]\n    output = output.transpose(0, 1) # [batch_size, max_len+1(=6), num_directions(=1) * n_hidden]\n    loss = 0\n    for i in range(0, len(target_batch)):\n        # output[i] : [max_len+1, num_directions(=1) * n_hidden, target_batch[i] : max_len+1]\n        loss += criterion(output[i], target_batch[i])\n    if (epoch + 1) % 1000 == 0:\n        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n    loss.backward()\n    optimizer.step()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hidden","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test\ndef translate(word):\n    input_batch, output_batch, _ = make_batch([[word, 'P' * len(word)]])\n\n    # make hidden shape [num_layers * num_directions, batch_size, n_hidden]\n    hidden = Variable(torch.zeros(1, 1, n_hidden))\n    output = model(input_batch, hidden, output_batch)\n    # output : [max_len+1(=6), batch_size(=1), n_class]\n\n    predict = output.data.max(2, keepdim=True)[1] # select n_class dimension\n    decoded = [char_arr[i] for i in predict]\n    end = decoded.index('E')\n    translated = ''.join(decoded[:end])\n\n    return translated.replace('P', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('test')\nprint('man ->', translate('man'))\nprint('mans ->', translate('mans'))\nprint('king ->', translate('king'))\nprint('black ->', translate('black'))\nprint('upp ->', translate('upp'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}