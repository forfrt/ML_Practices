{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-coding-edd8f1cf8f2d\nimport os\nimport numpy as np\nfrom collections import Counter\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"\ndef make_Dictionary(root_dir):\n    all_words = []\n    emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n    for mail in emails:\n        with open(mail) as m:\n            for line in m:\n                words = line.split()\n                all_words += words\n                \n    dictionary = Counter(all_words)\n    list_to_remove = dictionary.keys()\n    \n    for item in list_to_remove:\n        if item.isalpha() == False:\n            del dictionary[item]\n        elif len(item) == 1:\n            del dictionary[item]\n    dictionary = dictionary.most_common(3000)\n    \n    return dictionary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_features(mail_dir):\n    files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n    features_matrix = np.zeros((len(files),3000))\n    train_labels = np.zeros(len(files))\n    count = 0;\n    docID = 0;\n    \n    for fil in files:\n      with open(fil) as fi:\n        for i,line in enumerate(fi):\n          if i == 2:\n            words = line.split()\n            for word in words:\n              wordID = 0\n              for i,d in enumerate(dictionary):\n                if d[0] == word:\n                  wordID = i\n                  features_matrix[docID,wordID] = words.count(word)\n                    \n        train_labels[docID] = 0;\n        filepathTokens = fil.split('/')\n        lastToken = filepathTokens[len(filepathTokens) - 1]\n        \n        if lastToken.startswith(\"spmsg\"):\n            train_labels[docID] = 1;\n            count = count + 1\n        docID = docID + 1\n    return features_matrix, train_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cPickle\nimport gzip\ndef load(file_name):\n    # load the model\n    stream = gzip.open(file_name, \"rb\")\n    model = cPickle.load(stream)\n    stream.close()\n    return model\ndef save(file_name, model):\n    # save the model\n    stream = gzip.open(file_name, \"wb\")\n    cPickle.dump(model, stream)\n    stream.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DIR = \"../train-mails\"\nTEST_DIR = \"../test-mails\"\n\nprint \"reading and processing emails from file.\"\ndictionary = make_Dictionary(TRAIN_DIR)\n\nfeatures_matrix, labels = extract_features(TRAIN_DIR)\ntest_feature_matrix, test_labels = extract_features(TEST_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To save\nsave(\"/tmp/features_matrix\", features_matrix)\nsave(\"/tmp/labels\", labels)\nsave(\"/tmp/test_feature_matrix\", test_feature_matrix)\nsave(\"/tmp/test_labels\", test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To load\nfeatures_matrix = load(\"/tmp/features_matrix\")\nlabels = load(\"/tmp/labels\")\ntest_feature_matrix = load(\"/tmp/test_feature_matrix\")\ntest_labels = load(\"/tmp/test_labels\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = svm.SVC(kernel=\"rbf\", C=100, gamma=10)\n\nprint \"Training model.\"\n#train model\nmodel.fit(features_matrix, labels)\npredicted_labels = model.predict(test_feature_matrix)\n\nprint \"FINISHED classifying. accuracy score : \"\nprint accuracy_score(test_labels, predicted_labels)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}