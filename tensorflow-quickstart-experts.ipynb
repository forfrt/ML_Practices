{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# https://www.tensorflow.org/tutorials/quickstart/advanced","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\nfrom tensorflow.keras import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n# Add a channels dimension\nx_train = x_train[..., tf.newaxis]\nx_test = x_test[..., tf.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\na=np.random.random((2, 5))\nprint(a, type(a))\ni=3\nprint(a[..., i], type(a[..., i]))\nprint(a[:i], type(a[:i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds=tf.data.Dataset.from_tensor_slices(\n    (x_train, y_train)).shuffle(10000).batch(32)\n\ntest_ds=tf.data.Dataset.from_tensor_slices(\n    (x_test, y_test)).batch(32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyModel(Model):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.conv1=Conv2D(32, 3, activation='relu')\n        self.flatten=Flatten()\n        self.d1=Dense(128, activation='relu')\n        self.d2=Dense(10)\n        \n    def call(self, x):\n        x=self.conv1(x)\n        x=self.flatten(x)\n        x=self.d1(x)\n        return self.d2(x)\n    \nmodel=MyModel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_object=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\noptimizer=tf.keras.optimizers.Adam()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loss=tf.keras.metrics.Mean(name='train_loss')\ntrain_accuracy=tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n\ntest_loss = tf.keras.metrics.Mean(name='test_loss')\ntest_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef train_step(images, labels):\n    with tf.GradientTape() as tape:\n        predictions=model(images, training=True)\n        loss=loss_object(labels, predictions)\n        \n    gradients=tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    \n    train_loss(loss)\n    train_accuracy(labels, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef test_step(images, labels):\n    predictions=model(images, training=False)\n    t_loss=loss_object(labels, predictions)\n    \n    test_loss(t_loss)\n    test_accuracy(labels, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS=5\n\nfor epoch in range(EPOCHS):\n    train_loss.reset_states()\n    train_accuracy.reset_states()\n    \n    test_loss.reset_states()\n    test_accuracy.reset_states()\n    \n    for train_images, train_labels in train_ds:\n        train_step(train_images, train_labels)\n        \n    for test_images, test_labels in test_ds:\n        test_step(test_images, test_labels)\n        \n    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n    print(template.format(epoch + 1,\n                        train_loss.result(),\n                        train_accuracy.result() * 100,\n                        test_loss.result(),\n                        test_accuracy.result() * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}